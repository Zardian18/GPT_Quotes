{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOtyeyU7FgyVg4ee+3sivQ8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zardian18/GPT_Quotes/blob/master/GPT_quotes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hllts0W0PoG4"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "! mkdir ~/.kaggle\n",
        "!cp /content/drive/MyDrive/kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fw9nQ8ES-Ya",
        "outputId": "3e779ba1-ef55-4b4a-cd11-df75b30bd22c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d abireltaief/english-quotes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GM_0CSQuS_sj",
        "outputId": "b36960eb-c6db-43fb-bcc6-cfc3272bb89f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading english-quotes.zip to /content\n",
            "\r  0% 0.00/667k [00:00<?, ?B/s]\n",
            "\r100% 667k/667k [00:00<00:00, 136MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip english-quotes.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ-AmkuhTB0r",
        "outputId": "0eae3b76-bb0a-44ed-df0b-11128729609c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  english-quotes.zip\n",
            "  inflating: quotes.csv              \n",
            "  inflating: quotes.json             \n",
            "  inflating: quotes.jsonl            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "import string\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, losses, callbacks\n",
        "import pandas as pd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cip4V2ScTNbF",
        "outputId": "a7b1c127-846e-474b-ef0f-575cf55d9057"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 8000\n",
        "MAX_LEN = 50\n",
        "EMBEDDING_DIM = 256\n",
        "KEY_DIM = 512\n",
        "N_HEADS = 4\n",
        "FEED_FORWARD_DIM = 512\n",
        "VALIDATION_SPLIT = 0.2\n",
        "SEED = 42\n",
        "LOAD_MODEL = False\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 15"
      ],
      "metadata": {
        "id": "a7eMLq5GTPsD"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/quotes.csv\")\n",
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LG-Oz22RU6Y5",
        "outputId": "c6527a34-956b-4c84-9565-84feafce4487"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                              quote  \\\n",
              "0           0     “Be yourself; everyone else is already taken.”   \n",
              "1           1  “I'm selfish, impatient and a little insecure....   \n",
              "2           2  “Two things are infinite: the universe and hum...   \n",
              "3           3                   “So many books, so little time.”   \n",
              "4           4  “A room without books is like a body without a...   \n",
              "\n",
              "                  author                                               tags  \n",
              "0            Oscar Wilde  ['be-yourself', 'gilbert-perreira', 'honesty',...  \n",
              "1         Marilyn Monroe  ['best', 'life', 'love', 'mistakes', 'out-of-c...  \n",
              "2        Albert Einstein  ['human-nature', 'humor', 'infinity', 'philoso...  \n",
              "3            Frank Zappa                                 ['books', 'humor']  \n",
              "4  Marcus Tullius Cicero                        ['books', 'simile', 'soul']  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ead0e71e-e6cc-4e49-bae9-c802af2f5180\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>quote</th>\n",
              "      <th>author</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>“Be yourself; everyone else is already taken.”</td>\n",
              "      <td>Oscar Wilde</td>\n",
              "      <td>['be-yourself', 'gilbert-perreira', 'honesty',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>“I'm selfish, impatient and a little insecure....</td>\n",
              "      <td>Marilyn Monroe</td>\n",
              "      <td>['best', 'life', 'love', 'mistakes', 'out-of-c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>“Two things are infinite: the universe and hum...</td>\n",
              "      <td>Albert Einstein</td>\n",
              "      <td>['human-nature', 'humor', 'infinity', 'philoso...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>“So many books, so little time.”</td>\n",
              "      <td>Frank Zappa</td>\n",
              "      <td>['books', 'humor']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>“A room without books is like a body without a...</td>\n",
              "      <td>Marcus Tullius Cicero</td>\n",
              "      <td>['books', 'simile', 'soul']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ead0e71e-e6cc-4e49-bae9-c802af2f5180')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ead0e71e-e6cc-4e49-bae9-c802af2f5180 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ead0e71e-e6cc-4e49-bae9-c802af2f5180');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b6f82c4c-3d25-4903-a0f9-38906087f430\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b6f82c4c-3d25-4903-a0f9-38906087f430')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b6f82c4c-3d25-4903-a0f9-38906087f430 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quotes=df[\"quote\"]\n",
        "quotes.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBzcfkrzV4wF",
        "outputId": "6f7be90f-3776-4ae8-8455-6dddae0e040f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       “Be yourself; everyone else is already taken.”\n",
              "1    “I'm selfish, impatient and a little insecure....\n",
              "2    “Two things are infinite: the universe and hum...\n",
              "3                     “So many books, so little time.”\n",
              "4    “A room without books is like a body without a...\n",
              "Name: quote, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quotes_text =[]\n",
        "for i in range(len(quotes)):\n",
        "  quotes_text.append(quotes[i])"
      ],
      "metadata": {
        "id": "-F5wWfhCV9fq"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quotes_text[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJiGwR-hWAbo",
        "outputId": "2ba5ec15-87b7-4592-f2dc-03137b024c3f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['“Be yourself; everyone else is already taken.”',\n",
              " \"“I'm selfish, impatient and a little insecure. I make mistakes, I am out of control and at times hard to handle. But if you can't handle me at my worst, then you sure as hell don't deserve me at my best.”\",\n",
              " \"“Two things are infinite: the universe and human stupidity; and I'm not sure about the universe.”\"]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_punctuation(s):\n",
        "    s = re.sub(f\"([{string.punctuation}, '\\n'])\", r\" \\1 \", s)\n",
        "    s = re.sub(\" +\", \" \", s)\n",
        "    return s\n",
        "\n",
        "\n",
        "text_data = [pad_punctuation(x) for x in quotes_text]"
      ],
      "metadata": {
        "id": "tFPme-hhWNxm"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_data[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yU3UWv6WWcY7",
        "outputId": "9821ef6f-e4c0-4e25-a154-b7bcea840313"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['“Be yourself ; everyone else is already taken . ”',\n",
              " \"“I ' m selfish , impatient and a little insecure . I make mistakes , I am out of control and at times hard to handle . But if you can ' t handle me at my worst , then you sure as hell don ' t deserve me at my best . ”\",\n",
              " \"“Two things are infinite : the universe and human stupidity ; and I ' m not sure about the universe . ”\"]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices(text_data)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .shuffle(1000)\n",
        ")"
      ],
      "metadata": {
        "id": "_ZnjdVq4Wdrx"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mL-om8HWg2B",
        "outputId": "37772138-134a-471c-ee07-4e2adb37148b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_ShuffleDataset element_spec=TensorSpec(shape=(None,), dtype=tf.string, name=None)>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum =0\n",
        "for i in range(len(text_data)):\n",
        "  words = text_data[i].split()\n",
        "  sum += len(words)\n",
        "\n",
        "print(f\"Average words per quote: {sum/len(text_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0mYx1bnWinh",
        "outputId": "2000c6d8-9ef1-4fa0-bf3d-efe93841b368"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average words per quote: 38.77392344497608\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer = layers.TextVectorization(\n",
        "    standardize=\"lower\",\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=MAX_LEN + 1,\n",
        ")"
      ],
      "metadata": {
        "id": "v2FUe4yIWlka"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer.adapt(text_ds)\n",
        "vocab = vectorize_layer.get_vocabulary()"
      ],
      "metadata": {
        "id": "E-4L39EsWsgd"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, word in enumerate(vocab[:10]):\n",
        "    print(f\"{i}: {word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91WEwFksWuBU",
        "outputId": "d9b93324-387d-4c04-a012-ada63c9b66f3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: \n",
            "1: [UNK]\n",
            "2: .\n",
            "3: ,\n",
            "4: the\n",
            "5: you\n",
            "6: ”\n",
            "7: to\n",
            "8: and\n",
            "9: '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NM9gLEbvWvsv",
        "outputId": "e0303e9c-86e3-4140-bc64-96b0d244149c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7915"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_tokenised = vectorize_layer(text_data[1])\n",
        "print(example_tokenised.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAkNYFalWxDO",
        "outputId": "f4a8dd2d-f5d7-4604-b685-5f8e9cc147d4"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  51    9  106 2054    3 3106    8   10  149 2208    2   11   87  471\n",
            "    3   11   98   81   12  646    8   52  263  282    7 2231    2   26\n",
            "   41    5   27    9   22 2231   37   52   34  619    3   94    5  327\n",
            "   39  345   61    9   22  645   37   52   34]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_inputs(text):\n",
        "    text = tf.expand_dims(text, -1)\n",
        "    tokenized_sentences = vectorize_layer(text)\n",
        "    x = tokenized_sentences[:, :-1]\n",
        "    y = tokenized_sentences[:, 1:]\n",
        "    return x, y\n",
        "\n",
        "\n",
        "train_ds = text_ds.map(prepare_inputs)"
      ],
      "metadata": {
        "id": "DtdOouHTW8YE"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_inputs(text):\n",
        "    text = tf.expand_dims(text, -1)\n",
        "    tokenized_sentences = vectorize_layer(text)\n",
        "    x = tokenized_sentences[:, :-1]\n",
        "    y = tokenized_sentences[:, 1:]\n",
        "    return x, y\n",
        "\n",
        "\n",
        "train_ds = text_ds.map(prepare_inputs)"
      ],
      "metadata": {
        "id": "lw8yFVMGXBZ-"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_input_output = train_ds.take(1).get_single_element()"
      ],
      "metadata": {
        "id": "OFQNc5-nXIKi"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_input_output[0][0] # input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTqgMOwzXDS0",
        "outputId": "aafa73f8-2128-4ff7-afdb-bdc8bf76fce8"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int64, numpy=\n",
              "array([ 174,   20,   57,  830,   46, 6593, 6501,   66,  121, 2250,  260,\n",
              "         56,   42,   33,    4,  233,  153,    2,    6,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0])>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_input_output[1][0] #output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTnbwftYXKCB",
        "outputId": "38231095-f3ce-45c9-d113-47660b1cd545"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int64, numpy=\n",
              "array([  20,   57,  830,   46, 6593, 6501,   66,  121, 2250,  260,   56,\n",
              "         42,   33,    4,  233,  153,    2,    6,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0])>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_input_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZYRqiZMXT8y",
        "outputId": "9d1e263d-723e-4126-de68-a843e122c0c7"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(32, 50), dtype=int64, numpy=\n",
              " array([[ 174,   20,   57, ...,    0,    0,    0],\n",
              "        [ 284,    9,   22, ...,    0,    0,    0],\n",
              "        [ 267,    5,   44, ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [ 913, 1020,   75, ...,    0,    0,    0],\n",
              "        [ 129,   13,   10, ...,    0,    0,    0],\n",
              "        [ 129,    9,   23, ...,    2,    6,    0]])>,\n",
              " <tf.Tensor: shape=(32, 50), dtype=int64, numpy=\n",
              " array([[  20,   57,  830, ...,    0,    0,    0],\n",
              "        [   9,   22,  227, ...,    0,    0,    0],\n",
              "        [   5,   44,    3, ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [1020,   75,    4, ...,    0,    0,    0],\n",
              "        [  13,   10,  178, ...,    0,    0,    0],\n",
              "        [   9,   23,   19, ...,    6,    0,    0]])>)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def causal_attention_mask(batch_size, n_dest, n_src, dtype):\n",
        "    i = tf.range(n_dest)[:, None]\n",
        "    j = tf.range(n_src)\n",
        "    m = i >= j - n_src + n_dest\n",
        "    mask = tf.cast(m, dtype)\n",
        "    mask = tf.reshape(mask, [1, n_dest, n_src])\n",
        "    mult = tf.concat(\n",
        "        [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0\n",
        "    )\n",
        "    return tf.tile(mask, mult)"
      ],
      "metadata": {
        "id": "9zChir5KXYnf"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.transpose(causal_attention_mask(1, 10, 10, dtype=tf.int32)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TyqebkMXahp",
        "outputId": "c4d5306c-cdde-47fb-882d-3e85a43d9970"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "       [0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "       [0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
              "       [0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
              "       [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, num_heads, key_dim, embed_dim, ff_dim, dropout_rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.key_dim = key_dim\n",
        "        self.embed_dim = embed_dim\n",
        "        self.ff_dim = ff_dim\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.attn = layers.MultiHeadAttention(\n",
        "            num_heads, key_dim, output_shape=embed_dim\n",
        "        )\n",
        "        self.dropout_1 = layers.Dropout(self.dropout_rate)\n",
        "        self.ln_1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.ffn_1 = layers.Dense(self.ff_dim, activation=\"relu\")\n",
        "        self.ffn_2 = layers.Dense(self.embed_dim)\n",
        "        self.dropout_2 = layers.Dropout(self.dropout_rate)\n",
        "        self.ln_2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size = input_shape[0]\n",
        "        seq_len = input_shape[1]\n",
        "        causal_mask = causal_attention_mask(\n",
        "            batch_size, seq_len, seq_len, tf.bool\n",
        "        )\n",
        "        attention_output, attention_scores = self.attn(\n",
        "            inputs,\n",
        "            inputs,\n",
        "            attention_mask=causal_mask,\n",
        "            return_attention_scores=True,\n",
        "        )\n",
        "        attention_output = self.dropout_1(attention_output)\n",
        "        out1 = self.ln_1(inputs + attention_output)\n",
        "        ffn_1 = self.ffn_1(out1)\n",
        "        ffn_2 = self.ffn_2(ffn_1)\n",
        "        ffn_output = self.dropout_2(ffn_2)\n",
        "        return (self.ln_2(out1 + ffn_output), attention_scores)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"key_dim\": self.key_dim,\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "                \"num_heads\": self.num_heads,\n",
        "                \"ff_dim\": self.ff_dim,\n",
        "                \"dropout_rate\": self.dropout_rate,\n",
        "            }\n",
        "        )\n",
        "        return config"
      ],
      "metadata": {
        "id": "x_G7JkF6Xb3z"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, max_len, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.max_len = max_len\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "        self.token_emb = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.pos_emb = layers.Embedding(input_dim=max_len, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"max_len\": self.max_len,\n",
        "                \"vocab_size\": self.vocab_size,\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "            }\n",
        "        )\n",
        "        return config"
      ],
      "metadata": {
        "id": "y1xbhHvnXeHZ"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = layers.Input(shape=(None,), dtype=tf.int32)\n",
        "x = TokenAndPositionEmbedding(MAX_LEN, VOCAB_SIZE, EMBEDDING_DIM)(inputs)\n",
        "x, attention_scores = TransformerBlock(N_HEADS, KEY_DIM, EMBEDDING_DIM, FEED_FORWARD_DIM)(x)\n",
        "outputs = layers.Dense(VOCAB_SIZE, activation=\"softmax\")(x)\n",
        "\n",
        "gpt = models.Model(inputs= inputs, outputs= [outputs, attention_scores])\n",
        "gpt.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxnMShzaXfde",
        "outputId": "fb4ca526-f89a-4ea2-9821-20eef15741b5"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " token_and_position_embeddi  (None, None, 256)         2060800   \n",
            " ng_1 (TokenAndPositionEmbe                                      \n",
            " dding)                                                          \n",
            "                                                                 \n",
            " transformer_block_1 (Trans  ((None, None, 256),       2367488   \n",
            " formerBlock)                 (None, 4, None, None))             \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, None, 8000)        2056000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6484288 (24.74 MB)\n",
            "Trainable params: 6484288 (24.74 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt.compile(\"adam\", loss=[losses.SparseCategoricalCrossentropy(), None])"
      ],
      "metadata": {
        "id": "ch5KY0VbXnTt"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "class TextGenerator(callbacks.Callback):\n",
        "    def __init__(self, index_to_word, top_k=10):\n",
        "        self.index_to_word = index_to_word\n",
        "        self.word_to_index = {\n",
        "            word: index for index, word in enumerate(index_to_word)\n",
        "        }\n",
        "\n",
        "    def sample_from(self, probs, temperature):\n",
        "        probs = probs ** (1 / temperature)\n",
        "        probs = probs / np.sum(probs)\n",
        "        return np.random.choice(len(probs), p=probs), probs\n",
        "\n",
        "    def generate(self, start_prompt, max_tokens, temperature):\n",
        "        start_tokens = [\n",
        "            self.word_to_index.get(x, 1) for x in start_prompt.split()\n",
        "        ]\n",
        "        sample_token = None\n",
        "        info = []\n",
        "        while len(start_tokens) < max_tokens and sample_token != 0:\n",
        "            x = np.array([start_tokens])\n",
        "            y, att = self.model.predict(x, verbose=0)\n",
        "            sample_token, probs = self.sample_from(y[0][-1], temperature)\n",
        "            info.append(\n",
        "                {\n",
        "                    \"prompt\": start_prompt,\n",
        "                    \"word_probs\": probs,\n",
        "                    \"atts\": att[0, :, -1, :],\n",
        "                }\n",
        "            )\n",
        "            start_tokens.append(sample_token)\n",
        "            start_prompt = start_prompt + \" \" + self.index_to_word[sample_token]\n",
        "        print(f\"\\ngenerated text:\\n{start_prompt}\\n\")\n",
        "        return info\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "      wordx = random.choice(vocab)\n",
        "      self.generate(wordx, max_tokens=50, temperature=1.0)"
      ],
      "metadata": {
        "id": "_wpJmV--Xo-S"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
        "    filepath=\"./checkpoint/checkpoint.ckpt\",\n",
        "    save_weights_only=True,\n",
        "    save_freq=\"epoch\",\n",
        "    verbose=0,\n",
        ")\n",
        "\n",
        "tensorboard_callback = callbacks.TensorBoard(log_dir=\"./logs\")\n",
        "\n",
        "# Tokenize starting prompt\n",
        "text_generator = TextGenerator(vocab)"
      ],
      "metadata": {
        "id": "rZI9dKESXqpd"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt.fit(\n",
        "    train_ds,\n",
        "    epochs=50,\n",
        "    callbacks=[model_checkpoint_callback, tensorboard_callback, text_generator],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTkgCi6-XsNs",
        "outputId": "41cf16ba-6b6f-4041-a920-160b8c12c6f3"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            " 5/79 [>.............................] - ETA: 2s - loss: 2.3599 - dense_5_loss: 2.3599"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0228s vs `on_train_batch_end` time: 0.0291s). Check your callbacks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - ETA: 0s - loss: 2.2654 - dense_5_loss: 2.2654\n",
            "generated text:\n",
            "individual - gemstones ! how much thing , some part of god should be like your dad to never sleep . you are up all . if you . ” \n",
            "\n",
            "79/79 [==============================] - 5s 61ms/step - loss: 2.2654 - dense_5_loss: 2.2654\n",
            "Epoch 2/50\n",
            "77/79 [============================>.] - ETA: 0s - loss: 2.0268 - dense_5_loss: 2.0268\n",
            "generated text:\n",
            "neither is intense person who \n",
            "\n",
            "79/79 [==============================] - 3s 33ms/step - loss: 2.0281 - dense_5_loss: 2.0281\n",
            "Epoch 3/50\n",
            "79/79 [==============================] - ETA: 0s - loss: 1.8212 - dense_5_loss: 1.8212\n",
            "generated text:\n",
            "tremendous to be prisoner all of all that life : where i want to got to get to have my own - be worth fond of terrorjust ” \n",
            "\n",
            "79/79 [==============================] - 4s 49ms/step - loss: 1.8212 - dense_5_loss: 1.8212\n",
            "Epoch 4/50\n",
            "78/79 [============================>.] - ETA: 0s - loss: 1.6158 - dense_5_loss: 1.6158\n",
            "generated text:\n",
            "governments of mankind . . . is respect for a small men . . . . . . . . . . . . . . you had had ' ve had . it is a sail love i promised . . . . that ' ve lived all your\n",
            "\n",
            "79/79 [==============================] - 6s 71ms/step - loss: 1.6168 - dense_5_loss: 1.6168\n",
            "Epoch 5/50\n",
            "77/79 [============================>.] - ETA: 0s - loss: 1.4147 - dense_5_loss: 1.4147\n",
            "generated text:\n",
            "genuine is to be in the world . the face is holding someone who are not something you . for the soul ? you already think . ” \n",
            "\n",
            "79/79 [==============================] - 4s 50ms/step - loss: 1.4194 - dense_5_loss: 1.4194\n",
            "Epoch 6/50\n",
            "77/79 [============================>.] - ETA: 0s - loss: 1.2330 - dense_5_loss: 1.2330\n",
            "generated text:\n",
            "weird . we love we are these three , we face tighter . ” \n",
            "\n",
            "79/79 [==============================] - 3s 38ms/step - loss: 1.2309 - dense_5_loss: 1.2309\n",
            "Epoch 7/50\n",
            "79/79 [==============================] - ETA: 0s - loss: 1.0512 - dense_5_loss: 1.0512\n",
            "generated text:\n",
            "ended of enough . where wouldn ' t where 0 you . pride . ” \n",
            "\n",
            "79/79 [==============================] - 3s 39ms/step - loss: 1.0512 - dense_5_loss: 1.0512\n",
            "Epoch 8/50\n",
            "78/79 [============================>.] - ETA: 0s - loss: 0.8906 - dense_5_loss: 0.8906\n",
            "generated text:\n",
            "encouragingly is written in the face , even the future he will fill the stars . ” \n",
            "\n",
            "79/79 [==============================] - 4s 50ms/step - loss: 0.8906 - dense_5_loss: 0.8906\n",
            "Epoch 9/50\n",
            "77/79 [============================>.] - ETA: 0s - loss: 0.7428 - dense_5_loss: 0.7428\n",
            "generated text:\n",
            "curtainthrilled are not necessarily doubting , the outstretched hand ; the future belongs to the beauty out of the crowds for those who am so many their invisible man can satisfy , but this art and the desperate confidence that we ' s not enough of some ' t teach\n",
            "\n",
            "79/79 [==============================] - 5s 64ms/step - loss: 0.7457 - dense_5_loss: 0.7457\n",
            "Epoch 10/50\n",
            "78/79 [============================>.] - ETA: 0s - loss: 0.6290 - dense_5_loss: 0.6290\n",
            "generated text:\n",
            "buddha all was all the enjoyed , always have great wealth , \" said disagrees with a dictionary for each other day . find in the said . . \" isabelle shrugged . in spite of them . ” \n",
            "\n",
            "79/79 [==============================] - 4s 57ms/step - loss: 0.6305 - dense_5_loss: 0.6305\n",
            "Epoch 11/50\n",
            "78/79 [============================>.] - ETA: 0s - loss: 0.5368 - dense_5_loss: 0.5368\n",
            "generated text:\n",
            "egypt great books can ' t give enough of claimed you . in good , in perspective , in 2 . they will fall to change faithful friends all the time . ” \n",
            "\n",
            "79/79 [==============================] - 5s 60ms/step - loss: 0.5386 - dense_5_loss: 0.5386\n",
            "Epoch 12/50\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.4580 - dense_5_loss: 0.4580\n",
            "generated text:\n",
            "cancer , more than smiles a present . ” \n",
            "\n",
            "79/79 [==============================] - 3s 35ms/step - loss: 0.4580 - dense_5_loss: 0.4580\n",
            "Epoch 13/50\n",
            "77/79 [============================>.] - ETA: 0s - loss: 0.3939 - dense_5_loss: 0.3939\n",
            "generated text:\n",
            "“simplicity , patience , compassion . these three are lucky most on your secret , faith . the greatest enemy sense of your skin , and eternity . ” \n",
            "\n",
            "79/79 [==============================] - 4s 49ms/step - loss: 0.3939 - dense_5_loss: 0.3939\n",
            "Epoch 14/50\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.3479 - dense_5_loss: 0.3479\n",
            "generated text:\n",
            "horizons one that are gone , more powerful than these things â€“ defeat , become known struggle so struggle , and have loved , known you have loved before you have known defeat is moving . ” \n",
            "\n",
            "79/79 [==============================] - 5s 67ms/step - loss: 0.3479 - dense_5_loss: 0.3479\n",
            "Epoch 15/50\n",
            "78/79 [============================>.] - ETA: 0s - loss: 0.3064 - dense_5_loss: 0.3064\n",
            "generated text:\n",
            "struggles i walked back to myself that while to my lifeâ€™s hard energy for the invincible \" \" lookwhat happenswith a beautiful left . ” \n",
            "\n",
            "79/79 [==============================] - 4s 48ms/step - loss: 0.3073 - dense_5_loss: 0.3073\n",
            "Epoch 16/50\n",
            "78/79 [============================>.] - ETA: 0s - loss: 0.2765 - dense_5_loss: 0.2765\n",
            "generated text:\n",
            "deep swamps , in not - but not - called love dies , the not - and i am , not - called â€˜psychotically ; how to ' s an impossibility , but i cannot help myself . ” \n",
            "\n",
            "79/79 [==============================] - 5s 61ms/step - loss: 0.2770 - dense_5_loss: 0.2770\n",
            "Epoch 17/50\n",
            "78/79 [============================>.] - ETA: 0s - loss: 0.2525 - dense_5_loss: 0.2525\n",
            "generated text:\n",
            "socks only i didn ' t i felt as the surprise in the boy . \" he never did you . \" i did this . so throw off the bowlines . sail away from the can safe and wraps his fingers along . my throat is full of the\n",
            "\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.2527 - dense_5_loss: 0.2527\n",
            "Epoch 18/50\n",
            "77/79 [============================>.] - ETA: 0s - loss: 0.2305 - dense_5_loss: 0.2305\n",
            "generated text:\n",
            "leaveâ€”until is the may be it is the and the and future you so it is the simple dreams that ever see rightly ; what is invisible man is going . what is the sun by the wise can see where lucky about the present you this is the person\n",
            "\n",
            "79/79 [==============================] - 5s 69ms/step - loss: 0.2311 - dense_5_loss: 0.2311\n",
            "Epoch 19/50\n",
            "78/79 [============================>.] - ETA: 0s - loss: 0.2132 - dense_5_loss: 0.2132\n",
            "generated text:\n",
            "“from the moment i picked up your book until i put it down , i put up with you down , i put out with you down . ” \n",
            "\n",
            "79/79 [==============================] - 5s 61ms/step - loss: 0.2139 - dense_5_loss: 0.2139\n",
            "Epoch 20/50\n",
            "78/79 [============================>.] - ETA: 0s - loss: 0.1993 - dense_5_loss: 0.1993\n",
            "generated text:\n",
            "stringing the day came from a guy and a cluttered mind , of going , increases , as the best day . ” \n",
            "\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.1993 - dense_5_loss: 0.1993\n",
            "Epoch 21/50\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.1889 - dense_5_loss: 0.1889\n",
            "generated text:\n",
            "kiss a man you can should hate : or noble thing to her like to being shut out from her . ” \n",
            "\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.1889 - dense_5_loss: 0.1889\n",
            "Epoch 22/50\n",
            "78/79 [============================>.] - ETA: 0s - loss: 0.1751 - dense_5_loss: 0.1751\n",
            "generated text:\n",
            "compete me storm is you . someone who is you . ” \n",
            "\n",
            "79/79 [==============================] - 3s 40ms/step - loss: 0.1752 - dense_5_loss: 0.1752\n",
            "Epoch 23/50\n",
            "77/79 [============================>.] - ETA: 0s - loss: 0.1662 - dense_5_loss: 0.1662\n",
            "generated text:\n",
            "understanding we have ourselves are ourselves . ” \n",
            "\n",
            "79/79 [==============================] - 3s 35ms/step - loss: 0.1670 - dense_5_loss: 0.1670\n",
            "Epoch 24/50\n",
            "78/79 [============================>.] - ETA: 0s - loss: 0.1638 - dense_5_loss: 0.1638\n",
            "generated text:\n",
            "von homemaker has the ultimate career . all night to be seen what other careers exist , and all i could live . ” \n",
            "\n",
            "79/79 [==============================] - 4s 50ms/step - loss: 0.1641 - dense_5_loss: 0.1641\n",
            "Epoch 25/50\n",
            "78/79 [============================>.] - ETA: 0s - loss: 0.1602 - dense_5_loss: 0.1602\n",
            "generated text:\n",
            "“courage isn ' t having the strength to go on - it is going to go among others , mouthing knowledge without character from your pain . unless you may your choices you face might be . ” \n",
            "\n",
            "79/79 [==============================] - 6s 70ms/step - loss: 0.1604 - dense_5_loss: 0.1604\n",
            "Epoch 26/50\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.1541 - dense_5_loss: 0.1541\n",
            "generated text:\n",
            "matrimony is a part of a heart . ” \n",
            "\n",
            "79/79 [==============================] - 3s 35ms/step - loss: 0.1541 - dense_5_loss: 0.1541\n",
            "Epoch 27/50\n",
            "77/79 [============================>.] - ETA: 0s - loss: 0.1539 - dense_5_loss: 0.1539\n",
            "generated text:\n",
            "heartbeat like nothing like either , like iâ€˜ve thought out from night . happiness , nor to make it . ” \n",
            "\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.1539 - dense_5_loss: 0.1539\n",
            "Epoch 28/50\n",
            "77/79 [============================>.] - ETA: 0s - loss: 0.1552 - dense_5_loss: 0.1552\n",
            "generated text:\n",
            "sock get to choose by the face so late or what you can be . ” \n",
            "\n",
            "79/79 [==============================] - 3s 40ms/step - loss: 0.1550 - dense_5_loss: 0.1550\n",
            "Epoch 29/50\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.1523 - dense_5_loss: 0.1523\n",
            "generated text:\n",
            "superiority find sure you have step you have time use you can really time and narrow field . and see the human behavior . ” \n",
            "\n",
            "79/79 [==============================] - 4s 53ms/step - loss: 0.1523 - dense_5_loss: 0.1523\n",
            "Epoch 30/50\n",
            "78/79 [============================>.] - ETA: 0s - loss: 0.1545 - dense_5_loss: 0.1545\n",
            "generated text:\n",
            "times we need to follow happiness , no choice , remember becomes if you . ” \n",
            "\n",
            "79/79 [==============================] - 3s 41ms/step - loss: 0.1546 - dense_5_loss: 0.1546\n",
            "Epoch 31/50\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.1557 - dense_5_loss: 0.1557\n",
            "generated text:\n",
            "â€�â€œwhat refuse to be on the heart that you must be in saying me to step onto something in school . just never be able to do one really closes , \" \" what i did right here . ” \n",
            "\n",
            "79/79 [==============================] - 5s 58ms/step - loss: 0.1557 - dense_5_loss: 0.1557\n",
            "Epoch 32/50\n",
            "78/79 [============================>.] - ETA: 0s - loss: 0.1560 - dense_5_loss: 0.1560\n",
            "generated text:\n",
            "summarize is a it is better when it is not brave in fast to say better than is it is not to be very tired . ” \n",
            "\n",
            "79/79 [==============================] - 5s 59ms/step - loss: 0.1563 - dense_5_loss: 0.1563\n",
            "Epoch 33/50\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.1537 - dense_5_loss: 0.1537\n",
            "generated text:\n",
            "“growing working for what we could . that would be apart for a long , if make up the light was we all the spiritual inspiration . ” \n",
            "\n",
            "79/79 [==============================] - 4s 50ms/step - loss: 0.1537 - dense_5_loss: 0.1537\n",
            "Epoch 34/50\n",
            "77/79 [============================>.] - ETA: 0s - loss: 0.1548 - dense_5_loss: 0.1548\n",
            "generated text:\n",
            "somehow , when it is dark places ' s language and when you ' re right words are infinite tunnels . they ' re all staring at words , what you think , babies , miss you need courage , â€“ answered , there ' ve got to sleep ,\n",
            "\n",
            "79/79 [==============================] - 5s 65ms/step - loss: 0.1558 - dense_5_loss: 0.1558\n",
            "Epoch 35/50\n",
            "78/79 [============================>.] - ETA: 0s - loss: 0.1547 - dense_5_loss: 0.1547\n",
            "generated text:\n",
            "stretch many things alone , ever met in a multitude of reasons . it ' s wallflower . you die light gets things ! ” \n",
            "\n",
            "79/79 [==============================] - 4s 54ms/step - loss: 0.1545 - dense_5_loss: 0.1545\n",
            "Epoch 36/50\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.1457 - dense_5_loss: 0.1457\n",
            "generated text:\n",
            "Ø§Ù„Ø¢Ø®Ø±ÙˆÙ† insists upon us while to smile gratefully . there is death to be an invincible summer . but there is an chocolate now . ” \n",
            "\n",
            "79/79 [==============================] - 5s 57ms/step - loss: 0.1457 - dense_5_loss: 0.1457\n",
            "Epoch 37/50\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.1437 - dense_5_loss: 0.1437\n",
            "generated text:\n",
            "cautioning is what we read , one who loves ever loved , the grief , far more . and the more clearly we can seem so much stronger than we ' re like the bitterest . ” \n",
            "\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.1437 - dense_5_loss: 0.1437\n",
            "Epoch 38/50\n",
            "78/79 [============================>.] - ETA: 0s - loss: 0.1400 - dense_5_loss: 0.1400\n",
            "generated text:\n",
            "towards love life . when things happens and get people think it happens to their minds up like their own . ” \n",
            "\n",
            "79/79 [==============================] - 4s 47ms/step - loss: 0.1400 - dense_5_loss: 0.1400\n",
            "Epoch 39/50\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.1376 - dense_5_loss: 0.1376\n",
            "generated text:\n",
            "penalty vain have not to sit pride ; i need to do not want . ” \n",
            "\n",
            "79/79 [==============================] - 4s 49ms/step - loss: 0.1376 - dense_5_loss: 0.1376\n",
            "Epoch 40/50\n",
            "78/79 [============================>.] - ETA: 0s - loss: 0.1332 - dense_5_loss: 0.1332\n",
            "generated text:\n",
            "nerve is the least you can look into a song , but in the world , the himself , the collapsed feeling under your skin and no one thing that is no more walls . there you let fallen heart feeling that you rushed right through the moments where you\n",
            "\n",
            "79/79 [==============================] - 8s 103ms/step - loss: 0.1338 - dense_5_loss: 0.1338\n",
            "Epoch 41/50\n",
            "77/79 [============================>.] - ETA: 0s - loss: 0.1338 - dense_5_loss: 0.1338\n",
            "generated text:\n",
            "Ù„ÙŠØ³ don ' t care , \" clary said . \" he ' d do it for me . tell me he wouldn ' t . \" yes , ' t have . ” \n",
            "\n",
            "79/79 [==============================] - 4s 55ms/step - loss: 0.1340 - dense_5_loss: 0.1340\n",
            "Epoch 42/50\n",
            "77/79 [============================>.] - ETA: 0s - loss: 0.1353 - dense_5_loss: 0.1353\n",
            "generated text:\n",
            "finally your true mirror how the alive , you that they had broken heart can really are clean ! ” \n",
            "\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 0.1352 - dense_5_loss: 0.1352\n",
            "Epoch 43/50\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.1370 - dense_5_loss: 0.1370\n",
            "generated text:\n",
            "especially humans can do anything to let go . . sometimes the service of others . ” \n",
            "\n",
            "79/79 [==============================] - 4s 49ms/step - loss: 0.1370 - dense_5_loss: 0.1370\n",
            "Epoch 44/50\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.1344 - dense_5_loss: 0.1344\n",
            "generated text:\n",
            "hank people when people call go , when people call people talk , when felt , when people must go to seek , be amount , when i have loved another can think , and look up like to offer ; when i do not have rest said , like\n",
            "\n",
            "79/79 [==============================] - 5s 65ms/step - loss: 0.1344 - dense_5_loss: 0.1344\n",
            "Epoch 45/50\n",
            "78/79 [============================>.] - ETA: 0s - loss: 0.1331 - dense_5_loss: 0.1331\n",
            "generated text:\n",
            "recede the day we see the world is the plain : the last of the human wisdom cutting of . ” \n",
            "\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.1333 - dense_5_loss: 0.1333\n",
            "Epoch 46/50\n",
            "78/79 [============================>.] - ETA: 0s - loss: 0.1314 - dense_5_loss: 0.1314\n",
            "generated text:\n",
            "insight is afraid of greatness . some are born great , some achieve greatness , and others have greatness thrust upon them , and go in the end of them . ” \n",
            "\n",
            "79/79 [==============================] - 5s 60ms/step - loss: 0.1317 - dense_5_loss: 0.1317\n",
            "Epoch 47/50\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.1327 - dense_5_loss: 0.1327\n",
            "generated text:\n",
            "basically come , far better able to say a good thing it only one of your dreams according to your ability to our lives i have missed out of the only . ” \n",
            "\n",
            "79/79 [==============================] - 4s 53ms/step - loss: 0.1327 - dense_5_loss: 0.1327\n",
            "Epoch 48/50\n",
            "78/79 [============================>.] - ETA: 0s - loss: 0.1354 - dense_5_loss: 0.1354\n",
            "generated text:\n",
            "finethat be in love will be in love , to be in love , in love with when we love , is in love , and when will stay connected . sometimes i ' ll be good things happen , you . ” \n",
            "\n",
            "79/79 [==============================] - 5s 61ms/step - loss: 0.1355 - dense_5_loss: 0.1355\n",
            "Epoch 49/50\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.1352 - dense_5_loss: 0.1352\n",
            "generated text:\n",
            "astonished . tell about how careful you know about it . it ' s not what you know . ” \n",
            "\n",
            "79/79 [==============================] - 5s 60ms/step - loss: 0.1352 - dense_5_loss: 0.1352\n",
            "Epoch 50/50\n",
            "79/79 [==============================] - ETA: 0s - loss: 0.1377 - dense_5_loss: 0.1377\n",
            "generated text:\n",
            "views things , and things are not all those who cannot be around - - world through anything . ” \n",
            "\n",
            "79/79 [==============================] - 4s 49ms/step - loss: 0.1377 - dense_5_loss: 0.1377\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d447b5f3b20>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_data[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jjw6elHBXtyI",
        "outputId": "c82abbb3-a495-4c44-de52-c07bc6b8d3eb"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"“In three words I can sum up everything I ' ve learned about life : it goes on . ”\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_probs(info, vocab, top_k=5):\n",
        "    for i in info:\n",
        "        highlighted_text = []\n",
        "        for word, att_score in zip(\n",
        "            i[\"prompt\"].split(), np.mean(i[\"atts\"], axis=0)\n",
        "        ):\n",
        "            highlighted_text.append(\n",
        "                ''\n",
        "                + word\n",
        "                + \"\"\n",
        "            )\n",
        "        highlighted_text = \" \".join(highlighted_text)\n",
        "        display(HTML(highlighted_text))\n",
        "\n",
        "        word_probs = i[\"word_probs\"]\n",
        "        p_sorted = np.sort(word_probs)[::-1][:top_k]\n",
        "        i_sorted = np.argsort(word_probs)[::-1][:top_k]\n",
        "        for p, i in zip(p_sorted, i_sorted):\n",
        "            print(f\"{vocab[i]}:   \\t{np.round(100*p,2)}%\")\n",
        "        print(\"--------\\n\")"
      ],
      "metadata": {
        "id": "DsJ2SrsNY_1w"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info = text_generator.generate(\n",
        "    \"there\", max_tokens=50, temperature=1.0\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXg8gjBFZs_O",
        "outputId": "af17b53c-514e-4287-e191-5adb4b103976"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "generated text:\n",
            "there are troubles to than we can imagine . because they are the reason . ” \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_probs(info, vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9dRHKbi0Zx90",
        "outputId": "a98cbab6-ec2f-4eeb-e54c-f7dcc41975e1"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "there"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "is:   \t41.24%\n",
            "are:   \t32.63%\n",
            "':   \t20.61%\n",
            "may:   \t1.27%\n",
            "you:   \t0.82%\n",
            "--------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "there are"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no:   \t49.14%\n",
            "a:   \t6.26%\n",
            "always:   \t6.2%\n",
            "two:   \t3.27%\n",
            "wounds:   \t2.91%\n",
            "--------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "there are troubles"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "of:   \t69.85%\n",
            "for:   \t9.68%\n",
            "to:   \t8.3%\n",
            "when:   \t4.64%\n",
            "and:   \t1.15%\n",
            "--------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "there are troubles to"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "more:   \t37.08%\n",
            "sex:   \t22.0%\n",
            "come:   \t10.82%\n",
            "than:   \t10.01%\n",
            "me:   \t7.01%\n",
            "--------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "there are troubles to than"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "we:   \t26.92%\n",
            "and:   \t23.47%\n",
            "they:   \t18.12%\n",
            "a:   \t10.96%\n",
            "more:   \t10.29%\n",
            "--------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "there are troubles to than we"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "can:   \t84.06%\n",
            "':   \t5.49%\n",
            "live:   \t3.84%\n",
            "belong:   \t3.69%\n",
            "often:   \t0.77%\n",
            "--------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "there are troubles to than we can"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imagine:   \t42.42%\n",
            "only:   \t18.73%\n",
            "run:   \t11.03%\n",
            "not:   \t5.01%\n",
            "miss:   \t3.78%\n",
            "--------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "there are troubles to than we can imagine"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".:   \t99.37%\n",
            "that:   \t0.45%\n",
            "a:   \t0.09%\n",
            "it:   \t0.03%\n",
            "one:   \t0.02%\n",
            "--------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "there are troubles to than we can imagine ."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "”:   \t45.04%\n",
            "because:   \t36.84%\n",
            "one:   \t10.81%\n",
            "be:   \t3.6%\n",
            "make:   \t1.07%\n",
            "--------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "there are troubles to than we can imagine . because"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "they:   \t99.99%\n",
            "we:   \t0.01%\n",
            "he:   \t0.0%\n",
            "i:   \t0.0%\n",
            "you:   \t0.0%\n",
            "--------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "there are troubles to than we can imagine . because they"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "are:   \t85.5%\n",
            "':   \t4.64%\n",
            "aren:   \t4.29%\n",
            "have:   \t2.78%\n",
            "don:   \t0.87%\n",
            "--------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "there are troubles to than we can imagine . because they are"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no:   \t48.06%\n",
            "the:   \t27.07%\n",
            "one:   \t12.11%\n",
            ".:   \t10.87%\n",
            "only:   \t0.66%\n",
            "--------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "there are troubles to than we can imagine . because they are the"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "one:   \t78.08%\n",
            "perfect:   \t8.79%\n",
            "pain:   \t4.32%\n",
            "reason:   \t3.67%\n",
            "small:   \t0.74%\n",
            "--------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "there are troubles to than we can imagine . because they are the reason"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".:   \t96.63%\n",
            "and:   \t1.67%\n",
            "is:   \t1.24%\n",
            "for:   \t0.19%\n",
            "of:   \t0.13%\n",
            "--------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "there are troubles to than we can imagine . because they are the reason ."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "”:   \t100.0%\n",
            "they:   \t0.0%\n",
            "genius:   \t0.0%\n",
            "maybe:   \t0.0%\n",
            "just:   \t0.0%\n",
            "--------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "there are troubles to than we can imagine . because they are the reason . ”"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ":   \t100.0%\n",
            "words:   \t0.0%\n",
            "t:   \t0.0%\n",
            "you:   \t0.0%\n",
            "':   \t0.0%\n",
            "--------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "info = text_generator.generate(\n",
        "    \"believe\", max_tokens=50, temperature=1.0\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgkElXfXaJjY",
        "outputId": "b5e17d19-0eff-4cdd-dfb5-d6152114c538"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "generated text:\n",
            "believe in god , or joy is the kind of creating strength , but yourself . ” \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "info = text_generator.generate(\n",
        "    \"believe\", max_tokens=50, temperature=0.5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1x9iayVObCLT",
        "outputId": "b3aba0a3-a342-4452-d601-3afe04a5a922"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "generated text:\n",
            "believe in everything happens when people change that life is your way while you think it . ” \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "info = text_generator.generate(\n",
        "    \"success\", max_tokens=50, temperature=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMco7bAEbIC3",
        "outputId": "acbc4af1-cc2c-417f-acc9-fc53859dc6ca"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "generated text:\n",
            "success is not only the friend with hope a in the world acknowledges your strength . ” \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if \"power\" in vocab:\n",
        "  print(\"Yes\")\n",
        "\n",
        "else:\n",
        "  print(\"No\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D8XEKV7bWKs",
        "outputId": "90c74f90-94dc-42de-e3e7-4c9e7cd674bc"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "info = text_generator.generate(\n",
        "    \"wealth, fame, power\", max_tokens=50, temperature=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KjaBUanb6IL",
        "outputId": "2d8cd743-5ca6-4107-8958-8521ff494b28"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "generated text:\n",
            "wealth, fame, power are all these things : right words , and human life is . ” \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "info = text_generator.generate(\n",
        "    \"you are\", max_tokens=50, temperature=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4Rmgz6Uc-UC",
        "outputId": "f3e1d1da-dc84-4239-be56-12d2918ef0be"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "generated text:\n",
            "you are , and always have been , my dream . ” \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "info = text_generator.generate(\n",
        "    \"first things\", max_tokens=50, temperature=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7gkTrnrdQBo",
        "outputId": "aad33a58-2ccc-4240-cc04-f48ae99fe917"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "generated text:\n",
            "first things happen to you and so bad , you ' re broken open . ” \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "info = text_generator.generate(\n",
        "    \"it 's stupid\", max_tokens=50, temperature=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYqhRYCYd8H1",
        "outputId": "36deb310-4f4d-43a5-c146-3bb1604a42a3"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "generated text:\n",
            "it 's stupid , so we can ' t get part of madness . ” \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "info = text_generator.generate(\n",
        "    \"don' t laugh\", max_tokens=50, temperature=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWlMHTpaeDog",
        "outputId": "b431caae-8fdc-425c-b261-15813febcb3a"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "generated text:\n",
            "don' t laugh you lose your footing . ” \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "info = text_generator.generate(\n",
        "    \"gym\", max_tokens=50, temperature=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlYZsdACe78j",
        "outputId": "22ee7e2e-47fb-44c7-bb86-3c0d9ffd2327"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "generated text:\n",
            "gym love is not madness . ” \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "info = text_generator.generate(\n",
        "    \"gym\", max_tokens=50, temperature=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXmPIJUtfoP-",
        "outputId": "20491af6-fdfe-4cdb-b602-5a8b455ff89c"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "generated text:\n",
            "gym must be a mermaid , rango . i have no fear of depths and a great fear of shallow living . ” \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QtMcbH72fu3R"
      },
      "execution_count": 182,
      "outputs": []
    }
  ]
}